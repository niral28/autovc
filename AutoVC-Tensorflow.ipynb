{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 336, 128)\n",
      "(None, 128, 336)\n",
      "(None, 128, 512)\n",
      "(None, 128, 64)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "dim_neck = 32\n",
    "dim_embd = 256\n",
    "dim_pre = 512\n",
    "freq = 32\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(dim_embd+80, 128))\n",
    "x = inputs\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "print(x.shape)\n",
    "x = tf.transpose(x, perm=[0, 2, 1])\n",
    "print(x.shape)\n",
    "for i in range(3):\n",
    "    x = tf.keras.layers.Conv1D(512, kernel_size=5, strides=1, padding='same', dilation_rate=1, kernel_initializer=initializer)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "print(x.shape)\n",
    "rnn_cells = [tf.keras.layers.LSTMCell(dim_neck) for _ in range(2)]\n",
    "stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.RNN(stacked_lstm, return_sequences=True))(x)\n",
    "print(x.shape)\n",
    "outputs = x\n",
    "# informational bottleneck:\n",
    "output_forward = outputs[:, :, :dim_neck]\n",
    "output_backward = outputs[:, :, dim_neck:]\n",
    "codes = []\n",
    "for i in range(0, outputs.shape[1], freq):\n",
    "    codes.append(tf.concat((output_forward[:, i+freq-1, :],  output_backward[:, i, :]), axis=1))\n",
    "print(len(codes))\n",
    "encoder_model = tf.keras.Model(inputs=inputs, outputs=codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 320)\n",
      "(None, 128, 512)\n",
      "(None, 128, 512)\n",
      "(None, 128, 1024)\n",
      "(None, 128, 80)\n"
     ]
    }
   ],
   "source": [
    "# decoder\n",
    "inputs = tf.keras.Input(shape=(128,dim_neck*2+dim_embd,))\n",
    "print(inputs.shape)\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "x = tf.keras.layers.LSTM(dim_pre, return_sequences=True, kernel_initializer=initializer)(inputs)\n",
    "print(x.shape)\n",
    "for i in range(3):\n",
    "    x = tf.keras.layers.Conv1D(dim_pre, kernel_size=5, strides=1, padding='same', dilation_rate=1, kernel_initializer=initializer)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "print(x.shape)\n",
    "rnn_cells = [tf.keras.layers.LSTMCell(1024) for _ in range(2)]\n",
    "stacked_lstm = tf.keras.layers.StackedRNNCells(rnn_cells)\n",
    "x = tf.keras.layers.RNN(stacked_lstm, return_sequences=True)(x)\n",
    "print(x.shape)\n",
    "x = tf.keras.layers.Dense(80, kernel_initializer=initializer)(x)\n",
    "print(x.shape)\n",
    "decoder_model = tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postnet:\n",
    "inputs = tf.keras.Input(shape=(80,128))\n",
    "x = inputs\n",
    "x = tf.transpose(x, perm=[0, 2, 1])\n",
    "initializer = tf.keras.initializers.GlorotUniform()\n",
    "for i in range(4):\n",
    "    x = tf.keras.layers.Conv1D(dim_pre, kernel_size=5, strides=1, padding='same', dilation_rate=1, kernel_initializer=initializer)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('tanh')(x)\n",
    "x = tf.keras.layers.Conv1D(80, kernel_size=5, strides=1, padding='same', dilation_rate=1, kernel_initializer=initializer)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "postnet_model = tf.keras.Model(inputs=inputs, outputs=x, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaname = \"./data/spmel/train.pkl\"\n",
    "meta = pickle.load(open(metaname, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_item(item):\n",
    "    embeddings2 = item[1].reshape((1,256))\n",
    "    spectrogram = np.load(os.path.join('./data/spmel/',item[2]))[:128, :]\n",
    "    embeddingsFinal = np.repeat(embeddings2, spectrogram.shape[0], axis=0)\n",
    "    input_vector = tf.concat([spectrogram, embeddingsFinal], 1)\n",
    "    return tf.expand_dims(spectrogram,0), tf.expand_dims(tf.transpose(input_vector),0), tf.expand_dims(embeddingsFinal,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for bindx in range(0, len(meta),2):\n",
    "    spectrogram1, batch1, speaker_embeddings1 = preprocess_item(meta[bindx%(len(meta))])\n",
    "    spectrogram2, batch2, speaker_embeddings2 = preprocess_item(meta[(bindx+1)%(len(meta))])\n",
    "    datasets.append((tf.concat([spectrogram1, spectrogram2], 0), tf.concat([batch1, batch2], 0), tf.concat([speaker_embeddings1, speaker_embeddings2],0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.encoder = encoder_model\n",
    "        self.decoder = decoder_model\n",
    "        self.postnet = postnet_model \n",
    "    \n",
    "    def call(self, input_vector, c_target_embedding):\n",
    "        codes = self.encoder(input_vector)\n",
    "        \n",
    "        if c_target_embedding is None:\n",
    "            return tf.concat(codes, axis=-1)\n",
    "        \n",
    "        reshaped_encoder_output = []\n",
    "        for code in codes:\n",
    "            reshaped_encoder_output.append(tf.keras.layers.UpSampling1D(size=32)(tf.expand_dims(code,1)))\n",
    "        content_encoder_output = tf.concat(reshaped_encoder_output, axis=1)\n",
    "        decoder_input = tf.concat([content_encoder_output, c_target_embedding], 2)\n",
    "        # initial reconstruction \n",
    "        decoder_output = decoder_model(decoder_input)\n",
    "        postnet_input = tf.transpose(decoder_output, perm=[0, 2, 1])\n",
    "        # residual signal\n",
    "        postnet_output = postnet_model(postnet_input)\n",
    "        \n",
    "        # final reconstruction\n",
    "        mel_outputs_postnet = decoder_output + postnet_output\n",
    "        mel_outputs_postnet = tf.expand_dims(mel_outputs_postnet, 1)\n",
    "        decoder_output = tf.expand_dims(decoder_output, 1)\n",
    "        return decoder_output, mel_outputs_postnet, tf.concat(codes, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(x_real, x_identic, x_identic_psnt, code_real, code_reconst, lambda_cd = 1):\n",
    "\n",
    "    # Identity mapping loss\n",
    "#     print('r', x_real.shape)\n",
    "#     print('d', x_identic.shape)\n",
    "    \n",
    "#     print('cr', code_real.shape)\n",
    "#     print('cd', code_reconst.shape)\n",
    "    \n",
    "    g_loss_id = tf.reduce_sum(tf.losses.MSE(x_real, x_identic))   # initial reconstruction loss \n",
    "    g_loss_id_psnt = tf.reduce_sum(tf.losses.MSE(x_real, x_identic_psnt))    # final reconstruction loss\n",
    "\n",
    "    # Code semantic loss.\n",
    "    g_loss_cd = tf.reduce_sum(tf.abs(code_real - code_reconst)) # content loss\n",
    "    # Backward and optimize.\n",
    "    g_loss = g_loss_id + g_loss_id_psnt + lambda_cd * g_loss_cd\n",
    "    return g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.65227\n",
      "1778.359\n",
      "2524.7695\n",
      "478.6308\n",
      "332.5406\n",
      "322.28107\n",
      "882.9851\n",
      "317.3737\n",
      "177.3421\n",
      "108.668205\n",
      "118.43067\n",
      "174.929\n",
      "163.77689\n",
      "130.50208\n",
      "101.24489\n",
      "75.96875\n",
      "72.81986\n",
      "78.02751\n",
      "69.137436\n",
      "63.176796\n",
      "41.681847\n",
      "56.70675\n",
      "41.33048\n",
      "41.1098\n",
      "37.84527\n",
      "39.988533\n",
      "32.270115\n",
      "25.352692\n",
      "23.763119\n",
      "32.807606\n",
      "18.060375\n",
      "18.434517\n",
      "18.072582\n",
      "16.37901\n",
      "17.894497\n",
      "15.404562\n",
      "17.11672\n",
      "12.446261\n",
      "20.24604\n",
      "15.140363\n",
      "20.070145\n",
      "18.675774\n",
      "15.676472\n",
      "15.053728\n",
      "14.100948\n",
      "32.3348\n",
      "19.281826\n",
      "18.087326\n",
      "13.458249\n",
      "15.701824\n",
      "16.663118\n",
      "14.544374\n",
      "18.187054\n",
      "12.052452\n",
      "20.170856\n",
      "17.375175\n",
      "15.545654\n",
      "15.575114\n",
      "14.055098\n",
      "26.992523\n",
      "12.009029\n",
      "20.962233\n",
      "22.537811\n",
      "12.850964\n",
      "21.63469\n",
      "18.354195\n",
      "16.19212\n",
      "10.540262\n",
      "13.796022\n",
      "12.816151\n",
      "10.540093\n",
      "17.05465\n",
      "13.704038\n",
      "15.110298\n",
      "26.07969\n",
      "13.809831\n",
      "23.64678\n",
      "13.673296\n",
      "16.451088\n",
      "16.366478\n",
      "12.390549\n",
      "9.345935\n",
      "10.735006\n",
      "11.348434\n",
      "10.631867\n",
      "13.429095\n",
      "16.80453\n",
      "18.14264\n",
      "12.636705\n",
      "15.931704\n",
      "12.436508\n",
      "13.276863\n",
      "14.74565\n",
      "9.91959\n",
      "11.397389\n",
      "10.336385\n",
      "17.597437\n",
      "11.471576\n",
      "10.2523365\n",
      "16.33611\n",
      "18.809563\n",
      "9.860245\n",
      "14.8910675\n",
      "11.718979\n",
      "12.261621\n",
      "15.930567\n",
      "7.5244565\n",
      "13.298462\n",
      "14.946541\n",
      "14.671936\n",
      "11.3466015\n",
      "12.872178\n",
      "9.170392\n",
      "10.658096\n",
      "34.07974\n",
      "10.330539\n",
      "13.471758\n",
      "17.346409\n",
      "29.302025\n",
      "16.568913\n",
      "15.022297\n",
      "23.215977\n",
      "20.819035\n",
      "21.477837\n",
      "24.079082\n",
      "12.171749\n",
      "19.50523\n",
      "13.993807\n",
      "11.299269\n",
      "12.581271\n",
      "24.31802\n",
      "16.372375\n",
      "13.532605\n",
      "13.66394\n",
      "14.105364\n",
      "14.703676\n",
      "14.171394\n",
      "17.293152\n",
      "11.677383\n",
      "13.068303\n",
      "16.443886\n",
      "10.4781065\n",
      "24.060421\n",
      "8.197993\n",
      "13.63591\n",
      "8.545075\n",
      "11.102684\n",
      "14.007398\n",
      "21.556084\n",
      "15.885143\n",
      "18.120697\n",
      "19.95649\n",
      "10.912438\n",
      "16.789967\n",
      "14.430023\n",
      "11.708167\n",
      "11.494754\n",
      "19.53907\n",
      "24.270248\n",
      "14.637438\n",
      "32.999474\n",
      "32.923904\n",
      "22.45145\n",
      "28.138649\n",
      "23.637365\n",
      "20.94448\n",
      "35.30886\n",
      "27.31605\n",
      "16.661945\n",
      "17.477331\n",
      "15.867415\n",
      "14.920791\n",
      "22.228407\n",
      "17.500961\n",
      "15.174148\n",
      "13.855215\n",
      "14.032127\n",
      "26.241552\n",
      "16.592188\n",
      "18.90047\n",
      "17.795908\n",
      "17.779263\n",
      "10.948129\n",
      "19.057053\n",
      "17.39228\n",
      "11.272426\n",
      "17.08524\n",
      "13.811808\n",
      "13.631461\n",
      "13.779816\n",
      "9.010698\n",
      "20.396915\n",
      "14.618803\n",
      "30.283228\n",
      "16.64914\n",
      "10.459918\n",
      "7.2837753\n",
      "13.024121\n",
      "12.22115\n",
      "8.456639\n",
      "14.20068\n",
      "13.36982\n",
      "9.55088\n",
      "14.910836\n",
      "18.494804\n",
      "14.7241125\n",
      "9.524382\n",
      "9.646492\n",
      "10.124119\n",
      "16.22335\n",
      "16.576864\n",
      "16.028416\n",
      "13.204592\n",
      "19.751143\n",
      "13.700604\n",
      "9.25619\n",
      "10.157638\n",
      "18.96439\n",
      "10.492466\n",
      "13.037993\n",
      "11.098226\n",
      "11.829845\n",
      "20.008017\n",
      "13.424375\n",
      "11.856747\n",
      "16.755024\n",
      "9.815612\n",
      "16.40482\n",
      "13.20936\n",
      "9.25695\n",
      "11.399002\n",
      "21.944454\n",
      "9.795211\n",
      "21.17037\n",
      "17.489553\n",
      "13.057634\n",
      "9.320972\n",
      "15.932186\n",
      "14.813234\n",
      "12.634963\n",
      "12.134958\n",
      "13.36805\n",
      "12.246928\n",
      "10.650211\n",
      "9.809925\n",
      "14.919747\n",
      "11.084642\n",
      "10.706656\n",
      "11.934132\n",
      "8.913984\n",
      "11.38255\n",
      "8.462972\n",
      "15.535179\n",
      "12.177711\n",
      "14.229608\n",
      "15.733029\n",
      "9.273843\n",
      "10.144293\n",
      "14.398708\n",
      "25.918516\n",
      "14.735143\n",
      "30.57755\n",
      "9.159941\n",
      "19.92309\n",
      "22.344807\n",
      "13.256038\n",
      "22.176044\n",
      "21.393354\n",
      "23.780788\n",
      "21.14567\n",
      "24.067755\n",
      "19.070042\n",
      "16.764278\n",
      "16.574694\n",
      "15.554232\n",
      "20.798971\n",
      "13.307283\n",
      "46.206005\n",
      "20.859354\n",
      "13.782694\n",
      "14.036367\n",
      "11.787691\n",
      "17.405508\n",
      "21.904934\n",
      "15.660016\n",
      "14.901377\n",
      "19.749025\n",
      "16.67327\n",
      "14.084691\n",
      "16.125683\n",
      "14.261046\n",
      "20.187572\n",
      "17.989723\n",
      "11.329657\n",
      "14.671959\n",
      "15.903088\n",
      "12.058251\n",
      "12.858628\n",
      "27.01124\n",
      "16.07919\n",
      "23.57707\n",
      "21.884884\n",
      "10.485184\n",
      "24.608126\n",
      "15.927216\n",
      "10.736292\n",
      "23.38509\n",
      "12.372927\n",
      "11.398245\n",
      "24.991524\n",
      "16.511444\n",
      "11.9259205\n",
      "11.227478\n",
      "15.865347\n",
      "8.834425\n",
      "10.695501\n",
      "30.617725\n",
      "12.058357\n",
      "17.06844\n",
      "12.150375\n",
      "10.36022\n",
      "9.818869\n",
      "8.891388\n",
      "23.915928\n",
      "14.331812\n",
      "19.207172\n",
      "26.534132\n",
      "24.97726\n",
      "22.501762\n",
      "34.320976\n",
      "21.231445\n",
      "24.019646\n",
      "50.432205\n",
      "21.329355\n",
      "38.55184\n",
      "32.948906\n",
      "20.663822\n",
      "25.162636\n",
      "20.904951\n",
      "20.297365\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "num_iters = 1000\n",
    "loss_values = []\n",
    "for i in range(num_iters):\n",
    "    for x_real, input_vector, embeddings in datasets:\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_identic, x_identic_psnt, code_real = model(input_vector, embeddings)\n",
    "            code_reconst = model(input_vector, None)\n",
    "            loss = generator_loss(tf.expand_dims(x_real,1), x_identic, x_identic_psnt, code_real, code_reconst)\n",
    "            print(loss.numpy())\n",
    "            loss_values.append(loss.numpy())\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotib.pyplot as plt\n",
    "    plt.plot(range(num_iters), loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
